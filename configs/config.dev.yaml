port: 8000

llm:
  device: "cpu"
  embedding_path: "D:/LLM/BAAI/bge-large-zh-v1.5"
#  embedding_path: "D:/project/python_project/models/bge-large-zn-v1.5"

weaviate:
  url: "192.168.0.139"
  port: "8080"

vllm:
  model: "/root/autodl-tmp/llm/Qwen2-72B-Instruct-GPTQ-Int4"
  tensor_parallel_size: 4
  quantization: "gptq"
  seed: 42